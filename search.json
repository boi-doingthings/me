[
  {
    "objectID": "certificates.html",
    "href": "certificates.html",
    "title": "Certifications",
    "section": "",
    "text": "Technical Courses\n\nRust Programming\nMachine Learning Modeling Pipelines in Production\nMachine Learning Data Lifecycle in Production\nMarketing Analytics\nCustomer Segmentations\nCustomer Churn Prediction\nTime Series Analysis\nGeneralised Linear Models\nGeneralized AutoRegressive Conditional Heteroskedasticity (GARCH) Models"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yash Gupta",
    "section": "",
    "text": "Hi üëã ! I am Yash, currently working as a GPU Developer Advocate at Nvidia with the OpenHackathons Group. It is early days for me here as well, so will update more on my exact nature of work gradually ove time.\nPrior to this, I was a Manager & Lead Data Scientist with an unicorn startup Shiprocket in the realms of Logistics, Retail and E-Commerce.\nWith over half a decade of experience, I specialize in converting diverse data sets into impactful insights, applications, and products. My expertise lies in large-scale data processing, traditional machine learning, and deep learning architectures. Currently, I‚Äôm expanding my skills in Artificial Intelligence, with a particular focus on Generative AI applications in NLP. You can find more details about me here.\nPlease feel free to reach out to me over LinkedIn or X or have a few words with my AI assistant/secretary üòÑ. I am always up for interesting challenges and projects.\nThis website is made possible via Quatro."
  },
  {
    "objectID": "lists/movies.html",
    "href": "lists/movies.html",
    "title": "Movies",
    "section": "",
    "text": "Filmography\n\nDune\nInterstellar\nOppenheimer\n\n\n\nAction\n\nMad Max: Fury Road (2015)\nDie Hard (1988)\nThe Dark Knight (2008)\nGladiator (2000)\nTerminator 2: Judgment Day (1991)\nRaiders of the Lost Ark (1981)\nThe Matrix (1999)\nJohn Wick (2014)\n\n\n\nDrama\n\nThe Shawshank Redemption (1994)\nThe Godfather (1972)\n12 Angry Men (1957)\nSchindler‚Äôs List (1993)\nThe Godfather Part II (1974)\nOne Flew Over the Cuckoo‚Äôs Nest (1975)\nForrest Gump (1994)\nParasite (2019)\nFight Club (1999)\nGoodfellas (1990)\n\n\n\nComedy\n\nMonty Python and the Holy Grail (1975)\nAirplane! (1980)\nThe Big Lebowski (1998)\nDr.¬†Strangelove (1964)\nSome Like It Hot (1959)\nGroundhog Day (1993)\nAnnie Hall (1977)\nSuperbad (2007)\nThe Grand Budapest Hotel (2014)\nTootsie (1982)\n\n\n\nSci-Fi\n\nBlade Runner (1982)\n2001: A Space Odyssey (1968)\nStar Wars: Episode IV - A New Hope (1977)\nThe Empire Strikes Back (1980)\nArrival (2016)\nInterstellar (2014)\nThe Martian (2015)\nEx Machina (2014)\nA Clockwork Orange (1971)\nMinority Report (2002)\n\n\n\nHorror\n\nThe Exorcist (1973)\nPsycho (1960)\nThe Shining (1980)\nGet Out (2017)\nRosemary‚Äôs Baby (1968)\nHalloween (1978)\nHereditary (2018)\nThe Babadook (2014)\nA Nightmare on Elm Street (1984)\nThe Witch (2015)\n\n\n\nRomance\n\nCasablanca (1942)\nEternal Sunshine of the Spotless Mind (2004)\nLa La Land (2016)\nAm√©lie (2001)\nBefore Sunrise (1995)\nTitanic (1997)\nPride and Prejudice (2005)\nThe Notebook (2004)\nCall Me by Your Name (2017)\nRoman Holiday (1953)"
  },
  {
    "objectID": "lists/playlists.html",
    "href": "lists/playlists.html",
    "title": "Playlists",
    "section": "",
    "text": "Apple Music\n\nChill Time\n\nParty Mix\n\nDivine Chants \nClassic Collection\n\nMood Setter"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume and CV",
    "section": "",
    "text": "The upto date latest resume can be found at: https://drive.google.com/file/d/1h0VFtINFoqiNf1DJ8rpCWTyZB7l01peB/view?usp=drive_link\nThe detailed CV can be found at: https://boi-doingthings.notion.site/Curriculum-Vitae-a6e67eca3e394da38f1c10b87512b4a0"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Over time, I have got hands dirty in projects from multiple realms. Here is a snapshot."
  },
  {
    "objectID": "projects.html#professional",
    "href": "projects.html#professional",
    "title": "Projects",
    "section": "Professional",
    "text": "Professional\n\nGenerative AI\nAlgo/Tools/Libraries Used: langchain,GPTs, OpenAI, Vector DataStores,whisper,gpt-4,LLaMA\n\n[SRT] Engineered ‚ÄúSR-Copilot‚Äù, a RAG-based application, to streamline e-commerce and SR product interactions by efficiently addressing user queries and suggesting pertinent products and support ticket updates. Link\n[SRT] Prototyped an automated pipeline for processing customer support calls, rating interaction quality, transcribing content, identifying key pointers, and assessing buyer sentiment. (ASR‚ÜíNLP‚ÜíTTS)\nImpact: Reduced the number of agent call service requests by 7.6%.\n[SRT] Created a LLM-based chat app for non-technical stakeholders, to answer & execute database queries over Snowflake and Redshift in natural language.\n\n\n\nTabular Machine Learning\nAlgo/Tools/Libraries Used: pandas,polars,xgboost,catboost,scikit-learn,rapids,dask,AWS Sagemaker,S3,ELK\n\n[SRT] An ML pipeline that predicts a customers propensity to reject an ecommerce order at delivery. Link\nImpact: Saved over 35MM in shipping costs for over 250+ D2C sellers.\n[SRT] An ML solution combining NLP and tabular data analysis to identify fraudulent seller behaviors.\nImpact: Achieved 18% reduction in fraud cases of multiple categories (KYC, Weight Fraud etc).\n[WHJ] A classifier model to identify promising retention leads for sales pitch prioritization.\nImpact: Enhanced retention performance by 8%.\n[EXL] A suite of 12 ML models for an insurance client, that aims to mark a potential customers:\n\npropensity to respond and convert to a marketing campaign.\nestimated chargeable premium and loss ratio, if converted.\nImplemented an automated 1-window customer selection and offer allocation framework on top of models.\nImpact: The process boosted performance by +27%.\n\n\n\n\nNatural Language Processing\nAlgo/Tools/Libraries Used: PyTorch, BERT, Word2Vec, NER, nltk, flashtext, gensim, rapidfuzz,transformers,sentiment analysis,semantic search, clustering, text similarity\n\n[SRT] An unsupervised learning framework to enchance, standardise and validate over 6MM delivery addresses.\nImpact: A SoTA address intelligence agent that can successfully parse over 100K localities from 500+ Indian districts.\n[SRT] Developed an address deduplication and syntax correction pipeline, whole suite led to +20% increased deliveries.\nImpact: Successful identification of customers belonging to same household, leading to enhanced customer segmentations.\n\n[SRT] Engineered an intelligent system for instant product categorization, categorising over 1.3 million uniquely named products.\nImpact: Categorisation helped in better targeting for our other products.\n\n\n\nClustering and Segmentation\nAlgo/Tools/Libraries Used: DBSCAN,k-means,sklearn,ANOVA,noSQL,mongo\n\n[SRT] Created a custom seller segmentation for 100K+ D2C sellers registered on the platform.\n[SRT] Designed a novel clustering method to segregate over 100 million unique buyers for tagging and behavioral analysis.\n[WHJ] An SQL-based segmentation for improved student-teacher mappings, for better learning outcomes.\n\n\n\nForecasting and Geo-Spatial\nAlgo/Tools/Libraries Used: fb-prophet,time-series analysis, ARIMA, kepler, geopandas,scipy,statmodels,spatial-clustering\n\n[SRT] Probed hyper-local e-commerce geo-coordinate data to identify ideal locations for dark stores.\n\n[SRT] Undertook demand forecasting for fast moving goods for enhanced control over inventory and order management.\n\n\n\nMiscellaneous\nAlgo/Tools/Libraries Used: SQL,Redshift,Tableau,Snowflake,Excel,Google Workspace APIs\n\n[ALL] Data Pipelines to establish data for training and to update the features for inference.\n[ALL] Custom dashboards and reports in GSheets and Tableau to track performance of models and raise flags for changes.\n[EXL] Uncoverted unoptimised SAS-based code to R and Python modules, for faster processing and cheaper executions by saving license costs.\n[EXL] Optimised SQL data processing pipelines from Oracle to Redshift."
  },
  {
    "objectID": "projects.html#personal",
    "href": "projects.html#personal",
    "title": "Projects",
    "section": "Personal",
    "text": "Personal\n\nGenerative AI\n\nA audio to text ML app that converts expenses to JSON and builds a custom report. Link\n\n\n\nSoftware Development\n\nA bot that sends automated verses from Bhagvad Gita to a custom self maintained mailing lists.\nAn attempt to run a local file hosting via NextCloud and ad-blocker, pihole over my Raspberry Pi.\n\n\n\nSelf Hosting\n\nA dedicated setup running commonly used apps over a on premise system and exposed to custom domain. Link\n\nGithub: Repo"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Over the 5 years that I have been into Data Sciences and Machine Learning, the core thing I have learnt is to solve business problems. I am into building and executing solutions, that are fast paced and scalable. Unbounded by tech stacks, I aim to get systems up and running and establish quick feedback loops to generate lasting impact.\nAt Shiprocket, I have custom built data heavy and scalable ML pipelines, solving problems in realms of Tabular ML, NLP and time-series forecastings. I am also exploring interesting use cases that can be solved with the newly emergent field of GenAI, with disrupting postive impact to existing functions across business lines.\nBefore this, I had a short stint at Whitehat Jr. an Ed-Tech company, where I did a lot of clustering, segmentation and data crunching, besides building some dashboards (used by CxO folks).\nI began and evolved into data from EXL, where I transformed multiple slow and monolithic pre-existing data and machine learning projects built in propriety tools into fast, modular, interpretable and user-friendly solutions.\nIn general, I command strong hold in building and setting up data intensive solutions. Some of my key projects are listed here. I also undertake courses and certifications to keep myself up to date with this rapidly evolving domain.\nI have no defined interests üôà and take up and try different things. Trying to keep a memoir here. Besides that, I am a watch afficionado and üç∫ buff.\nI also try to maintain some lists for my:\n\nplaylists üéµ\n\nbooks üìñ\n\nmovies üé•\n\nwebsites üåê"
  }
]